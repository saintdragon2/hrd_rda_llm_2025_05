{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 로컬에서 임베딩 + RAG 구현하기\n",
    "\n",
    "## 로컬 임베딩 모델 사용 (BGE-m3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-4.1.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: tqdm in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from sentence-transformers) (4.67.1)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers)\n",
      "  Using cached torch-2.7.0-cp312-none-macosx_11_0_arm64.whl.metadata (29 kB)\n",
      "Collecting scikit-learn (from sentence-transformers)\n",
      "  Using cached scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl.metadata (31 kB)\n",
      "Collecting scipy (from sentence-transformers)\n",
      "  Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from sentence-transformers) (0.31.2)\n",
      "Requirement already satisfied: Pillow in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Collecting setuptools (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached setuptools-80.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (1.14.0)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers)\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Collecting safetensors>=0.4.3 (from transformers<5.0.0,>=4.41.0->sentence-transformers)\n",
      "  Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers)\n",
      "  Using cached threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.4.26)\n",
      "Using cached sentence_transformers-4.1.0-py3-none-any.whl (345 kB)\n",
      "Using cached torch-2.7.0-cp312-none-macosx_11_0_arm64.whl (68.6 MB)\n",
      "Using cached transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "Using cached scikit_learn-1.6.1-cp312-cp312-macosx_12_0_arm64.whl (11.2 MB)\n",
      "Using cached scipy-1.15.3-cp312-cp312-macosx_14_0_arm64.whl (22.4 MB)\n",
      "Using cached joblib-1.5.0-py3-none-any.whl (307 kB)\n",
      "Using cached safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Using cached threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached setuptools-80.4.0-py3-none-any.whl (1.2 MB)\n",
      "Installing collected packages: threadpoolctl, setuptools, scipy, safetensors, networkx, joblib, torch, scikit-learn, transformers, sentence-transformers\n",
      "Successfully installed joblib-1.5.0 networkx-3.4.2 safetensors-0.5.3 scikit-learn-1.6.1 scipy-1.15.3 sentence-transformers-4.1.0 setuptools-80.4.0 threadpoolctl-3.6.0 torch-2.7.0 transformers-4.51.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../chap04_summary_document/data/생성형 AI 기반의 영농 의사결정 지원 시스템 개발과 향후계획.pdf\n",
      "../chap04_summary_document/data/농업용 저수지 치수능력 증대를 위한 기존 사례 검토.pdf\n",
      "../chap04_summary_document/data/인공지능을 활용한 농업기반시설물 안전점검 방안.pdf\n",
      "../chap04_summary_document/data/인공지능 기법을 활용한 농촌지역의 객체 정보 추출방안.pdf\n",
      "../chap04_summary_document/data/포화 불균일성을 고려한 육계사 쿨링패드 시스템 성능 평가.pdf\n",
      "../chap04_summary_document/data/APEX 모델을 이용한 옥수수-가을배추 재배지의 시비 수준별 비점오염 부하량 평가.pdf\n",
      "../chap04_summary_document/data/저수지 제체 월류수위 예측을 위한 Fuzzy Time Series법의 적용성 비교 평가.pdf\n",
      "../chap04_summary_document/data/재난 관리용 고해상도 지형 데이터 자동 생성 방법 제안.pdf\n",
      "../chap04_summary_document/data/기후변화 대응 농업시설물의 신뢰성 기반 설계.pdf\n"
     ]
    }
   ],
   "source": [
    "from glob import glob \n",
    "\n",
    "for g in glob('../chap04_summary_document/data/*.pdf'):\n",
    "    print(g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "def read_pdf_and_split_text(pdf_path, chunk_size=1000, chunk_overlap=100):\n",
    "    \"\"\"\n",
    "    주어진 PDF 파일을 읽고 텍스트를 분할합니다.\n",
    "    매개변수:\n",
    "        pdf_path (str): PDF 파일의 경로.\n",
    "        chunk_size (int, 선택적): 각 텍스트 청크의 크기. 기본값은 1000입니다.\n",
    "        chunk_overlap (int, 선택적): 청크 간의 중첩 크기. 기본값은 100입니다.\n",
    "    반환값:\n",
    "        list: 분할된 텍스트 청크의 리스트.\n",
    "    \"\"\"\n",
    "    print(f\"PDF: {pdf_path} -----------------------------\")\n",
    "\n",
    "    pdf_loader = PyPDFLoader(pdf_path)\n",
    "    data_from_pdf = pdf_loader.load()\n",
    "\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=chunk_size, chunk_overlap=chunk_overlap\n",
    "    )\n",
    "\n",
    "    splits = text_splitter.split_documents(data_from_pdf)\n",
    "    \n",
    "    print(f\"Number of splits: {len(splits)}\\n\")\n",
    "    return splits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceBgeEmbeddings\n",
    "\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "model_kwargs = {\"device\": \"mps\"}  # 🔴 M1/M2/M3/M4 맥북은 'mps'\n",
    "encode_kwargs = {\"normalize_embeddings\": True}\n",
    "\n",
    "hf = HuggingFaceBgeEmbeddings(\n",
    "    model_name=model_name,\n",
    "    model_kwargs=model_kwargs,\n",
    "    encode_kwargs=encode_kwargs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pypdf\n",
      "  Downloading pypdf-5.5.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Downloading pypdf-5.5.0-py3-none-any.whl (303 kB)\n",
      "Installing collected packages: pypdf\n",
      "Successfully installed pypdf-5.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Chroma store\n",
      "PDF: ../chap04_summary_document/data/생성형 AI 기반의 영농 의사결정 지원 시스템 개발과 향후계획.pdf -----------------------------\n",
      "Number of splits: 12\n",
      "\n",
      "PDF: ../chap04_summary_document/data/농업용 저수지 치수능력 증대를 위한 기존 사례 검토.pdf -----------------------------\n",
      "Number of splits: 13\n",
      "\n",
      "PDF: ../chap04_summary_document/data/인공지능을 활용한 농업기반시설물 안전점검 방안.pdf -----------------------------\n",
      "Number of splits: 13\n",
      "\n",
      "PDF: ../chap04_summary_document/data/인공지능 기법을 활용한 농촌지역의 객체 정보 추출방안.pdf -----------------------------\n",
      "Number of splits: 17\n",
      "\n",
      "PDF: ../chap04_summary_document/data/포화 불균일성을 고려한 육계사 쿨링패드 시스템 성능 평가.pdf -----------------------------\n",
      "Number of splits: 36\n",
      "\n",
      "PDF: ../chap04_summary_document/data/APEX 모델을 이용한 옥수수-가을배추 재배지의 시비 수준별 비점오염 부하량 평가.pdf -----------------------------\n",
      "Number of splits: 61\n",
      "\n",
      "PDF: ../chap04_summary_document/data/저수지 제체 월류수위 예측을 위한 Fuzzy Time Series법의 적용성 비교 평가.pdf -----------------------------\n",
      "Number of splits: 44\n",
      "\n",
      "PDF: ../chap04_summary_document/data/재난 관리용 고해상도 지형 데이터 자동 생성 방법 제안.pdf -----------------------------\n",
      "Number of splits: 79\n",
      "\n",
      "PDF: ../chap04_summary_document/data/기후변화 대응 농업시설물의 신뢰성 기반 설계.pdf -----------------------------\n",
      "Number of splits: 32\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "persist_directory='./chroma_store'\n",
    "\n",
    "if os.path.exists(persist_directory):\n",
    "    print(\"Loading existing Chroma store\")\n",
    "    vectorstore = Chroma(\n",
    "        persist_directory=persist_directory, \n",
    "        embedding_function=hf\n",
    "    )\n",
    "else:\n",
    "    print(\"Creating new Chroma store\")\n",
    "    \n",
    "    vectorstore = None\n",
    "    for g in glob('../chap04_summary_document/data/*.pdf'):\n",
    "        chunks = read_pdf_and_split_text(g)\n",
    "        # 100개씩 나눠서 저장\n",
    "        for i in range(0, len(chunks), 100):\n",
    "            if vectorstore is None:\n",
    "                vectorstore = Chroma.from_documents(\n",
    "                    documents=chunks[i:i+100],\n",
    "                    embedding=hf,\n",
    "                    persist_directory=persist_directory\n",
    "                )\n",
    "            else:\n",
    "                vectorstore.add_documents(\n",
    "                    documents=chunks[i:i+100]\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'creationdate': '2024-06-07T10:12:03+08:00', 'creator': 'PyPDF', 'moddate': '2024-06-07T10:19:41+08:00', 'page': 4, 'page_label': '5', 'producer': 'Adobe PDF Library 10.0.1; modified using iTextSharp™ 5.5.0 ©2000-2013 iText Group NV (AGPL-version)', 'source': '../chap04_summary_document/data/생성형 AI 기반의 영농 의사결정 지원 시스템 개발과 향후계획.pdf', 'total_pages': 8}\n",
      "6▶\n",
      "그림 5. AI 팜두레 첫 화면 – 기본 예시 질문 결과\n",
      "Rural Resources\n",
      "+\n",
      "특집    생성형 AI 기반의 영농 의사결정 지원 시스템 개발과 향후계획\n",
      "그림 4. AI 팜두레 instruction 작성\n",
      "{'creationdate': '2024-06-07T10:12:10+08:00', 'creator': 'PyPDF', 'moddate': '2024-06-07T10:19:42+08:00', 'page': 0, 'page_label': '1', 'producer': 'Adobe PDF Library 10.0.1; modified using iTextSharp™ 5.5.0 ©2000-2013 iText Group NV (AGPL-version)', 'source': '../chap04_summary_document/data/인공지능 기법을 활용한 농촌지역의 객체 정보 추출방안.pdf', 'total_pages': 7}\n",
      "10▶\n",
      "인공지능 기법을 활용한 농촌지역의 \n",
      "객체 정보 추출방안\n",
      "1. 머리말\n",
      "최근 4차 산업혁명 기술이 경제 화두로 부상한 이후 3D, 빅데이터, IoT, \n",
      "AI를 활용한 사업들이 성장세를 띄고 있으며, 특히 AI 기술은 스마트도시, \n",
      "스마트건설, 보건복지, 안전 등 다양한 분야로 활용되고 있다. 이러한 4차 \n",
      "산업혁명 기술은 농업 및 농촌분야에서도 빠르게 적용되고 있다. 농촌분야\n",
      "에서는 ICT, 공간빅데이터 등을 활용해 증거기반 주민체감형 지역개발과 \n",
      "같은 지능형 스마트 농촌을 구현하기 위한 연구가 수행되고 있으며, 농업\n",
      "분야에서는 빅데이터, AI, 사물인터넷 등 ICT 기술을 접목한 스마트팜 연\n",
      "구가 수행되고 있다. 이처럼 농업과 농촌 분야에 신기술의 도입으로 학문\n",
      "분야의 확장과 새로운 비즈니스를 창출하고 있다. \n",
      "이러한 변화속에서 정부는 농촌공간의 쾌적성과 편리성을 높이고, 농촌\n",
      "주민 삶의 질 향상을 위해 농산촌 지원강화 및 성장환경 조성이라는 국정\n",
      "목표를 세우고, 이에 대한 세부실천 목표를 제시하였다. 이 가운데 하나가 \n",
      "농촌공간 재구조화 계획이다. 이 계획은 농촌공간의 여건에 따라 주거·\n",
      "생산·서비스 등 기능적으로 구분되고 재배치될 수 있도록 장기계획 수립 \n",
      "및 농촌특화지구 도입을 목표로 하고 있다. 이를 위해 「농촌공간 재구조화 \n",
      "및 재생지원을 위한 법률」(농촌공간재구조화법)을 22년도에 제정하였으며, \n",
      "24년부터 시행에 들어가게 된다. 또한 장기적인 계획에 대응하여 서비스 \n",
      "거점 확충, 주거지 인접 공장·축사 정비·집적화 등을 지원하는 농촌재생 \n",
      "프로젝트를 추진하고자 하고 있다. \n",
      "농촌지역을 대상으로 국정목표에 따른 세부실천과제를 수행하기 위해서\n",
      "는 기존의 현황에 대한 파악이 우선되어야 한다. 현재 우리나라의 농촌지\n",
      "역에 해당하는 공간은 국토기본법, 국토의 계획 및 이용에 관한 법률(국토\n",
      "02\n",
      "전 정 배\n",
      "공간정보연구원 \n",
      "/ 선임연구원\n",
      "jbjeon@lx.or.kr\n",
      "석 승 원\n",
      "전북대학교 스마트팜학과 \n",
      "/ 학사과정\n",
      "champ9162@jbnu.ac.kr\n",
      "{'creationdate': '2024-06-07T10:12:03+08:00', 'creator': 'PyPDF', 'moddate': '2024-06-07T10:19:41+08:00', 'page': 1, 'page_label': '2', 'producer': 'Adobe PDF Library 10.0.1; modified using iTextSharp™ 5.5.0 ©2000-2013 iText Group NV (AGPL-version)', 'source': '../chap04_summary_document/data/생성형 AI 기반의 영농 의사결정 지원 시스템 개발과 향후계획.pdf', 'total_pages': 8}\n",
      "업데이트 소식으로 가득하다. 우리 기관에서도 생\n",
      "성형 AI가 스마트농업에 게임체인저가 될 수 있을\n",
      "지 기대가 크다. 생성형 AI 유료 결제를 요청하는 \n",
      "모든 직원에게 비용을 지불하고 윤리교육 및 활\n",
      "용 교육 등 각종 교육프로그램을 개설하고 있으며 \n",
      "AI 활용 경진대회를 여는 등 농업 분야 발전을 위\n",
      "그림 1. 팜두레(farmdure) UI\n",
      "{'author': '', 'creationdate': '2024-09-03T09:47:48+09:00', 'creator': '', 'keywords': '', 'moddate': '2024-09-26T15:04:33+08:00', 'page': 5, 'page_label': '6', 'producer': 'Adobe PDF Library 10.0.1; modified using iTextSharp™ 5.5.0 ©2000-2013 iText Group NV (AGPL-version)', 'source': '../chap04_summary_document/data/인공지능을 활용한 농업기반시설물 안전점검 방안.pdf', 'subject': '', 'title': '', 'total_pages': 7}\n",
      "경을 구축하는 데 필수적인 요소가 될 것으로 예\n",
      "상된다. 제시된 연구와 사례가 농업기반시설물의 \n",
      "안전 점검과 유지보수 분야에서 실질적인 도움을 \n",
      "제공하고, 더 나아가 농업과 농촌의 지속 가능한 \n",
      "발전을 위한 중요한 발판이 되기를 기대한다.\n",
      "참고문헌\n",
      "1.   김정집, 임재윤, 김성화, 정회경, 2023, 인공지능 \n",
      "기반 구조물 안전관리 예측 시스템, 한국지식정\n",
      "보기술학회 논문집, 18(2) 247-257.\n",
      "2.   김지호, 김경영, 김동주, 2023, 건축물 점검을 위\n",
      "그림 8. 결함검출 결과(백태, 슬러지, 누수, 파손)\n",
      "{'creationdate': '2024-06-07T10:12:03+08:00', 'creator': 'PyPDF', 'moddate': '2024-06-07T10:19:41+08:00', 'page': 2, 'page_label': '3', 'producer': 'Adobe PDF Library 10.0.1; modified using iTextSharp™ 5.5.0 ©2000-2013 iText Group NV (AGPL-version)', 'source': '../chap04_summary_document/data/생성형 AI 기반의 영농 의사결정 지원 시스템 개발과 향후계획.pdf', 'total_pages': 8}\n",
      "답하는 직원 검색 웹앱을 만들어보았다(그림 2)\n",
      "2. \n",
      "이때가 생성형 AI 기반의 영농 의사결정 지원 서\n",
      "비스 가능성을 확인한 순간이다.\n",
      "2)  OpenAI의 Assistant AI를 이용해 쳇봇 시스템을 만들었다. 다\n",
      "음 Youtube 동영상을 참고하였다. https://www.youtube.\n",
      "com/watch?v=3_UYupYCeSc \n",
      "그림 2. GPT4.0-Turbo 기반으로 만든 농촌진흥청 직원 검색 웹앱. 질문에 대해 글을  \n",
      "읽고 적절한 답변을 해준다. 다만 GPT가 한 번 답변할 때마다 내 피 같은 돈  \n",
      "약 80원이 차감되므로 URL은 공개하지 않겠다.\n",
      "Rural Resources\n",
      "+\n",
      "특집    생성형 AI 기반의 영농 의사결정 지원 시스템 개발과 향후계획\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})\n",
    "\n",
    "chunks = retriever.invoke(\"AI가 농업분야에서 어떻게 활용될 수 있는지 설명해줘\")\n",
    "\n",
    "for chunk in chunks:\n",
    "    print(chunk.metadata)\n",
    "    print(chunk.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
