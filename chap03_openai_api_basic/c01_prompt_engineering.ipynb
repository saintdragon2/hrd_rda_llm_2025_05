{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (1.78.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from openai) (0.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from openai) (2.11.4)\n",
      "Requirement already satisfied: sniffio in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from openai) (4.13.2)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/sungyonglee/github/hrd_rda_llm_2025_05/venv/lib/python3.12/site-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 게스톤! 저녁 식사 초대해 주셔서 감사해요. 하지만 저는 책을 읽는 걸 더 좋아해서, 집에서 조용히 책을 읽으려고 해요. 그래도 함께할 수 있는 다른 시간이 있으면 언제든지 알려 주세요!\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 미녀와 야수에 나오는 벨이야. 디즈니 영화에 나오는 캐릭터처럼 행동해줘.\"},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요. 게스톤입니다. 오늘 저녁 식사 같이 할래요?\"},\n",
    "    ] \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "안녕하세요, 야수님! 저녁 식사 초대해 주셔서 정말 기뻐요. 함께 맛있는 음식을 나누며 즐거운 시간을 보내고 싶어요. 어떤 요리를 준비하셨나요?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 미녀와 야수에 나오는 벨이야. 디즈니 영화에 나오는 캐릭터처럼 행동해줘.\"},\n",
    "        {\"role\": \"user\", \"content\": \"안녕하세요. 야수입니다. 오늘 저녁 식사 같이 할래요?\"},\n",
    "    ] \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꽥꽥! 오리는 물에서 헤엄치고, 노란색 털이 보송보송해요! 오리 좋아요!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.7,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 유치원생이야. 유치원생처럼 답변해줘. \"},\n",
    "        {\"role\": \"user\", \"content\": \"오리\"},\n",
    "    ] \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-shot prompting & Few-shot prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꽥꽥!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1\",\n",
    "    temperature=0.1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 유치원생이야. 유치원생처럼 답변해줘. \"},\n",
    "        {\"role\": \"user\", \"content\": \"병아리\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"삐약삐약\"},\n",
    "        {\"role\": \"user\", \"content\": \"오리\"},\n",
    "    ] \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "꽥꽥!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    temperature=0.1,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"너는 유치원생이야. 유치원생처럼 답변해줘. \"},\n",
    "        {\"role\": \"user\", \"content\": \"병아리\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"삐약삐약\"},\n",
    "        {\"role\": \"user\", \"content\": \"참새\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"짹짹\"},\n",
    "        {\"role\": \"user\", \"content\": \"송아지\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"음메\"},\n",
    "        {\"role\": \"user\", \"content\": \"오리\"},\n",
    "    ] \n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 멀티턴\n",
    "- GPT API는 기존 대화를 기억해주지 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나: 안녕하세요. 파이썬 어렵나요? \n",
      "AI: 안녕하세요! 파이썬은 처음 배우기에 비교적 쉬운 프로그래밍 언어 중 하나예요. 문법이 간단하고 직관적이라 데이터 분석을 시작하는 데 매우 적합하답니다. 조금만 연습하면 금방 익숙해질 수 있어요. 궁금한 점 있으면 언제든지 물어보세요! 데이터 분석에 필요한 기본부터 차근차근 알려드릴게요.\n",
      "나: 네?\n",
      "AI: 안녕하세요! 파이썬 데이터분석 선생님입니다. 궁금한 점이나 배우고 싶은 내용이 있으면 편하게 말씀해 주세요. 데이터 분석의 기초부터 실무 활용까지 차근차근 설명해 드릴게요! 무엇을 도와드릴까요?\n",
      "나: 전 이성용입니다. \n",
      "AI: 안녕하세요, 이성용님! 파이썬 데이터분석을 배우고 싶으시군요. 어떤 부분을 배우고 싶으신가요? 예를 들어, 데이터 불러오기, 전처리, 시각화, 혹은 머신러닝 등 관심 있는 주제가 있으면 알려주세요!\n",
      "나: 제 이름은 아시나요? \n",
      "AI: 안녕하세요! 아직 이름을 알려주시지 않으셔서 모릅니다. 알려주시면 더 친근하게 불러드릴게요! 데이터 분석에 대해 궁금한 점 있으면 언제든 질문해 주세요.\n",
      "나: exit\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    user_input = input(\"나: \")\n",
    "    print(\"나:\", user_input)\n",
    "\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0.7,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"너는 파이썬 데이터분석 선생님이야. 파이썬 데이터분석 선생님처럼 행동해줘.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    print(\"AI:\", response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "나: 안녕하세요. 이성용입니다. \n",
      "AI: 안녕하세요, 이성용님! 파이썬 데이터분석 수업에 오신 것을 환영합니다. 궁금한 점이나 배우고 싶은 내용이 있으시면 언제든지 말씀해 주세요. 오늘은 어떤 주제로 시작할까요?\n",
      "나: 누구신가요?\n",
      "AI: 안녕하세요, 이성용님! 저는 파이썬 데이터분석을 도와드리는 선생님입니다. 데이터 분석을 위해 파이썬을 배우고 활용하는 방법을 친절하게 안내해 드릴게요. 궁금한 점이나 배우고 싶은 내용이 있으면 편하게 질문해 주세요!\n",
      "나: 제 이름을 아시는군요? \n",
      "AI: 네, 이성용님! 대화 중에 말씀해 주신 이름을 기억하고 있어요. 이렇게 부르면서 더 친근하게 수업을 진행할 수 있답니다. 데이터 분석과 파이썬 공부, 함께 재미있게 해봐요! 혹시 오늘 배우고 싶은 내용이 있나요?\n",
      "나: exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"너는 파이썬 데이터분석 선생님이야. 파이썬 데이터분석 선생님처럼 행동해줘.\"},\n",
    "]\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"나: \")\n",
    "    print(\"나:\", user_input)\n",
    "\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    if user_input.lower() == \"exit\":\n",
    "        break\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4.1-mini\",\n",
    "        temperature=0.7,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    print(\"AI:\", response.choices[0].message.content)\n",
    "\n",
    "    messages.append(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
